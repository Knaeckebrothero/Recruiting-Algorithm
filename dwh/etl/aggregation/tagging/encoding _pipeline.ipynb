{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T17:51:17.414527Z",
     "start_time": "2024-06-17T17:51:13.378719Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "def process_experience(experience_dict: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Function to preprocess an experience from a LinkedIn profile by cleaning text fields.\n",
    "    The function extracts the company, title, description, and location fields from the input dictionary.\n",
    "    It then cleans up the text by removing extra whitespace and new line characters.\n",
    "    \n",
    "    :param experience_dict: A dictionary containing profile information.\n",
    "\n",
    "    :return: A preprocessed dictionary with cleaned text fields.\n",
    "    \"\"\"\n",
    "    # Define the keys to extract and clean\n",
    "    keys_to_extract = ['company', 'title', 'description', 'location']\n",
    "    \n",
    "    # Initialize an empty dictionary to store the preprocessed data\n",
    "    preprocessed_data = {}\n",
    "    \n",
    "    # Iterate through the required keys\n",
    "    for key in keys_to_extract:\n",
    "        # Extract the value from the profile dictionary or use an empty string if the key is not present\n",
    "        value = experience_dict.get(key, '')\n",
    "        \n",
    "        # Clean up text\n",
    "        if value:\n",
    "            cleaned_value = re.sub(r'\\s+', ' ', value.strip())\n",
    "        else:\n",
    "            cleaned_value = None\n",
    "        \n",
    "        # Store the cleaned value in the preprocessed data dictionary\n",
    "        preprocessed_data[key] = cleaned_value\n",
    "    \n",
    "    # Return the preprocessed data\n",
    "    return preprocessed_data\n",
    "\n",
    "\n",
    "def prepare_experience_for_model_input(preprocessed_dict: dict, system_prompt: str, tokenizer: AutoTokenizer) -> dict:\n",
    "    \"\"\"\n",
    "    Function to prepare the model input based on the preprocessed dictionary.\n",
    "    The function constructs a prompt message using the system prompt and the preprocessed dictionary.\n",
    "    It then tokenizes the prompt using the provided tokenizer and returns the input IDs for the model.\n",
    "\n",
    "    :param preprocessed_dict: The preprocessed experience as a dictionary.\n",
    "    :param system_prompt: The prompt to use for the model input.\n",
    "    :param tokenizer: The tokenizer to use for encoding the input.\n",
    "\n",
    "    :return: The input IDs for the model (aka the tokens).\n",
    "    \"\"\"\n",
    "    # Convert the preprocessed dictionary to a JSON string and construct the prompt\n",
    "    prompt_messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(preprocessed_dict, indent=None)},\n",
    "    ]\n",
    "\n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        prompt_messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Return the input IDs\n",
    "    return input_ids\n",
    "\n",
    "\n",
    "def preprocess_and_save_experiences(input_file_path, output_path, system_prompt: str, model_id_or_path: str):\n",
    "    \"\"\"\n",
    "    Function to preprocess a JSON file containing the LinkedIn profiles and save the processed data to a new file.\n",
    "    The function reads the input JSON file, preprocesses the experiences, and prepares the model input.\n",
    "    It then saves the processed data to a new JSON file (object id + list of encoded experiences).\n",
    "    \n",
    "    :param input_file_path: The path to the input JSON file.\n",
    "    :param output_path: The path to save the output JSON file.\n",
    "    :param system_prompt: The prompt to use for the model input.\n",
    "    :param model_id_or_path: The identifier or path for the model to use for tokenization.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store the processed results\n",
    "    total_results = []\n",
    "    \n",
    "    # Load the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id_or_path)\n",
    "    \n",
    "    # Open and load the JSON file\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    # Initialize counter\n",
    "    profile_counter = 0\n",
    "\n",
    "    # Iterate over each profile in the data\n",
    "    for profile in data:\n",
    "        # Initialize a counter for every profile\n",
    "        experience_list_counter = 1\n",
    "        \n",
    "        # Iterate over each experience in the profile\n",
    "        for experience in profile[\"experiences\"]:            \n",
    "            # Preprocess the experience\n",
    "            preprocessed_experience = process_experience(experience)\n",
    "            \n",
    "            # Prepare the experience for the model input\n",
    "            encoded_experience = prepare_experience_for_model_input(\n",
    "                preprocessed_dict=preprocessed_experience, \n",
    "                system_prompt=system_prompt,\n",
    "                tokenizer=tokenizer,\n",
    "            )\n",
    "            \n",
    "            # Serialize each experience individually and save it to a file\n",
    "            torch.save(encoded_experience, f'{output_path}/input_{profile[\"_id\"][\"$oid\"]}_{experience_list_counter}.pt')\n",
    "            \n",
    "            # Up the counter\n",
    "            experience_list_counter += 1\n",
    "        \n",
    "        # Up and print profile counter\n",
    "        profile_counter += 1\n",
    "        print(profile_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85881f361b655874",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:41:34.399892Z",
     "start_time": "2024-06-15T11:41:34.382728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before processing:\n",
      "{'company': 'University of Engineering and Technology Peshawar, Pakistan', 'title': 'R&D Consultant', 'description': 'UET, Peshawar has undertaken various projects that required the expertise of a R&D based Biomedical Engineer. I provided my expertise to the students and staff in these projects and increased the productivity of the department. \\n\\nAdditionally, I\\n• Identified the need for 3D printers for the department\\n• Investigated 3D printers that would be best suited for the training individuals\\n• Designed a certified course to train the students and staff on the essentials of 3D printing\\n• Trained individuals including but not limited to, students, professionals and artists', 'location': 'Pakistan'}\n",
      "\n",
      "After processing:\n",
      "{'company': 'University of Engineering and Technology Peshawar, Pakistan', 'title': 'R&D Consultant', 'description': 'UET, Peshawar has undertaken various projects that required the expertise of a R&D based Biomedical Engineer. I provided my expertise to the students and staff in these projects and increased the productivity of the department. Additionally, I • Identified the need for 3D printers for the department • Investigated 3D printers that would be best suited for the training individuals • Designed a certified course to train the students and staff on the essentials of 3D printing • Trained individuals including but not limited to, students, professionals and artists', 'location': 'Pakistan'}\n",
      "Before processing:\n",
      "{'company': 'Google', 'title': 'Software Engineering Intern', 'description': None, 'location': 'Venice, California'}\n",
      "\n",
      "After processing:\n",
      "{'company': 'Google', 'title': 'Software Engineering Intern', 'description': None, 'location': 'Venice, California'}\n"
     ]
    }
   ],
   "source": [
    "test_experiences = [{\n",
    "      \"company\": \"University of Engineering and Technology Peshawar, Pakistan\",\n",
    "      \"title\": \"R&D Consultant\",\n",
    "      \"description\": \"UET, Peshawar has undertaken various projects that required the expertise of a R&D based Biomedical Engineer. I provided my expertise to the students and staff in these projects and increased the productivity of the department. \\n\\nAdditionally, I\\n• Identified the need for 3D printers for the department\\n• Investigated 3D printers that would be best suited for the training individuals\\n• Designed a certified course to train the students and staff on the essentials of 3D printing\\n• Trained individuals including but not limited to, students, professionals and artists\",\n",
    "      \"location\": \"Pakistan\"\n",
    "    },\n",
    "    {\n",
    "      \"company\": \"Google\",\n",
    "      \"title\": \"Software Engineering Intern\",\n",
    "      \"description\": None,\n",
    "      \"location\": \"Venice, California\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for experience in test_experiences:\n",
    "    print(\"Before processing:\")\n",
    "    print(experience)\n",
    "    print(\"\\nAfter processing:\")\n",
    "    print(process_experience(experience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dae0c886bf2ee5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:41:37.456929Z",
     "start_time": "2024-06-15T11:41:37.224221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded input:\n",
      "tensor([[128000, 128006,   9125, 128007,    271,   2675,    527,    459,  15592,\n",
      "          18328,  28175,    304,  42118,  11704,    505,  33867,  21542,     13,\n",
      "           3277,   3984,    449,    459,   3217,     11,    701,   3465,    374,\n",
      "            311,  14532,    323,   8819,   1401,   3649,     11,  21760,    389,\n",
      "          49183,    539,   1120,  11720,   7512,    719,   1101,  18479,   6305,\n",
      "             11,   4279,   5064,  12659,     11,    323,    279,    503,  71921,\n",
      "           1511,    304,    279,  10706,    627,   2520,    279,   2728,   3217,\n",
      "             11,   7068,    264,   4823,   1665,    430,   5764,   8365,   1778,\n",
      "            439,   5064,     11,   4913,     11,   7512,     11,    323,   9681,\n",
      "             13,    578,  33289,   1288,   8881,   2225,   9539,  11224,   7512,\n",
      "            323,  68695,   7512,   3196,    389,    279,   2317,    323,   5064,\n",
      "          40851,     13,  21829,    279,   2768,   8365,    369,    279,   2612,\n",
      "            512,  71616,     25,   9934,    311,   7836,  10743,    505,   2883,\n",
      "            955,    477,   2316,     11,    422,    539,   6089,   9932,    627,\n",
      "          19105,   1362,     25,  23673,    505,    279,   2683,   2316,    323,\n",
      "           4096,    627,  47761,     25,   1796,   2225,   2167,    320,  94732,\n",
      "            398,   9932,      8,    323,  25636,    320,  54340,  11383,   5938,\n",
      "            449,    279,   3560,    477,   5064,   4390,  16309,     25,  30834,\n",
      "           9959,  21513,     11,   2225,  11156,    323,  66251,     11,    430,\n",
      "           7664,    279,   3217,    477,    527,   5938,    449,    279,   5064,\n",
      "            627,   5207,   4823,  14692,     25,   5324,  71864,    794,   4145,\n",
      "          71864,  21841,    330,  97235,    794,   4145,  97235,  21841,    330,\n",
      "          54340,    794,   4482,     27,  30554,     16,  21841,   4145,  30554,\n",
      "             17,  21841,   2564,   1145,    330,  14412,    794,   4482,     27,\n",
      "           4681,     16,  21841,   4145,   4681,     17,  21841,   2564,  24333,\n",
      "            644,   1162,    459,   7180,    374,  14188,   9932,   6463,   8196,\n",
      "             11,    743,   1202,    907,    311,    854,     13,  73177,    279,\n",
      "           1988,  87388,    311,   8819,    279,   9959,   2038,   2085,   6968,\n",
      "            477,  26619,   3649,    539,   3118,    304,    279,   1988,    627,\n",
      "          12834,    420,   9659,    690,    387,   7373,  28598,    279,   1217,\n",
      "            690,   1193,   3493,    264,   4823,   1665,   2085,    904,   4726,\n",
      "          11470,    323,  25283,   1193,    279,  13239,   1988,     13,   5884,\n",
      "           2612,    430,   3250,   9011,  48092,     83,   1833,    279,   5300,\n",
      "           4823,   3645,     11,   4250,    387,  15590,   4726,    323,    690,\n",
      "           1464,    279,   5429,     13,   2100,     11,   1304,   2771,    311,\n",
      "           2744,  49553,    311,    279,   4823,   3645,    912,   5030,     13,\n",
      "           1789,   3187,     11,    422,    279,   1988,   5151,   6782,    912,\n",
      "             11,   7515,  38759,    477,  40815,   1495,     11,    499,   7068,\n",
      "            264,   4823,    449,    682,   8365,    439,    854,     13,  20474,\n",
      "            311,    539,   4018,    477,  11857,    904,   8365,    315,    279,\n",
      "            471,   3645,    627,   8586,    374,    459,   3187,    369,   1268,\n",
      "            279,   2077,    311,    264,   2728,   1988,   2643,   1427,   1093,\n",
      "            512,  13617,   1988,     25,   5324,  10348,    794,    330,  18788,\n",
      "          76521,   3907,    498,    330,   2150,    794,    330,   6777,  12092,\n",
      "          22103,    498,    330,   4789,    794,    330,   1622,  28423,     25,\n",
      "           1144,     77,   1734,     16,     13,   2755,  11330,   4236,    304,\n",
      "          31320,  22772,  27692,   4375,    369,  35269,  28317,  18825,     13,\n",
      "           1144,     77,     17,     13,   7735,   1601,    287,  40786,     11,\n",
      "          66288,  20070,    323,  31474,   3575,  22581,  16079,    369,  28317,\n",
      "          18825,    358,     11,  29363,    744,  18825,     11,  35269,  28317,\n",
      "            498,    330,   2588,    794,    330,  33763,  42031,     11,  21571,\n",
      "             11,   7427,  17122,  13617,   2077,     25,   5324,  71864,    794,\n",
      "            330,  37838,    498,    330,  97235,    794,    330,    668,  12092,\n",
      "          18328,    498,    330,  54340,    794,   4482,  12307,  13291,    498,\n",
      "            330,  87803,  10278,    990,    498,    330,  42716,   8735,    498,\n",
      "            330,  33359,    498,    330,  35686,  99246,   8073,    330,  14412,\n",
      "            794,   4482,    359,   3050,    498,    330,    668,  12092,  13291,\n",
      "            498,    330,  12307,  20392,    498,    330,  14717,    990,    498,\n",
      "            330,  19493,   8535,  46121,    498,    330,     66,  38368,   6492,\n",
      "            498,    330,  42716,   8735,    498,    330,  33359,    498,    330,\n",
      "          35686,  99246,  16079,    498,    330,  19493,   8535,  16622,   6492,\n",
      "            498,    330,  23603,   6067,  93546, 128009, 128006,    882, 128007,\n",
      "            271,   5018,  10348,    794,    330,  31272,    315,  17005,    323,\n",
      "          12053,    393,   4385,    675,    277,     11,  17076,    498,    330,\n",
      "           2150,    794,    330,     49,  33465,  56546,    498,    330,   4789,\n",
      "            794,    330,     52,   1372,     11,    393,   4385,    675,    277,\n",
      "            706,  45179,   5370,   7224,    430,   2631,    279,  19248,    315,\n",
      "            264,    432,  33465,   3196,  12371,  61860,  29483,     13,    358,\n",
      "           3984,    856,  19248,    311,    279,   4236,    323,   5687,    304,\n",
      "           1521,   7224,    323,   7319,    279,  26206,    315,    279,   9476,\n",
      "             13,  23212,     11,    358,   1144,     84,   2366,     17,  97437,\n",
      "            279,   1205,    369,    220,     18,     35,  57053,    369,    279,\n",
      "           9476,   1144,     84,   2366,     17,  33180,    660,    220,     18,\n",
      "             35,  57053,    430,   1053,    387,   1888,  32599,    369,    279,\n",
      "           4967,   7931,   1144,     84,   2366,     17,  48525,    264,  23759,\n",
      "           3388,    311,   5542,    279,   4236,    323,   5687,    389,    279,\n",
      "          59886,    315,    220,     18,     35,  18991,   1144,     84,   2366,\n",
      "             17,   1183,   2692,   7931,   2737,    719,    539,   7347,    311,\n",
      "             11,   4236,     11,  15749,    323,  13820,    498,    330,   2588,\n",
      "            794,    330,  89335,   9388, 128009, 128006,  78191, 128007,    271]])\n",
      "\n",
      "Decoded input:\n",
      "system\n",
      "\n",
      "You are an AI assistant specialized in analyzing experiences from LinkedIn profiles. When provided with an experience, your task is to interpret and extract key details, focusing on recognizing not just explicit skills but also implicit ones, common industry practices, and the jargon used in the sector.\n",
      "For the given experience, generate a JSON object that includes attributes such as industry, profession, skills, and tags. The extraction should reflect both clearly stated skills and inferred skills based on the context and industry norms. Consider the following attributes for the output:\n",
      "Industry: Try to deduce from company type or title, if not directly mentioned.\n",
      "Profession: Extract from the job title and description.\n",
      "Skills: List both direct (explicitly mentioned) and indirect (skills typically associated with the role or industry).\n",
      "Tags: Include relevant keywords, both technical and contextual, that describe the experience or are associated with the industry.\n",
      "Output JSON Template: {\"industry\": \"<industry>\", \"profession\": \"<profession>\", \"skills\": [\"<skill1>\", \"<skill2>\",...], \"tags\": [\"<tag1>\", \"<tag2>\",...]}\n",
      "In case an attribute is neither mentioned nor obvious, set its value to null. Interpret the input responsibly to extract the relevant information without creating or assuming details not present in the input.\n",
      "Since this generation will be fully automated the user will only provide a JSON object without any further instructions and expects only the resulting input. Any output that doesnâ€™t follow the specified JSON format, cannot be processed further and will break the script. So, make sure to always adhere to the JSON format no matter. For example, if the input fields contain no, garbled or irrelevant text, you generate a JSON with all attributes as null. Remember to not cut or alter any attributes of the return format.\n",
      "Here is an example for how the response to a given input might look like:\n",
      "Example input: {\"company\": \"Old Dominion University\", \"title\": \"Teaching Assistant\", \"description\": \"Key responsibilities: \\n\\n1. Assisting students in executing experimental laboratory works for Electronic Circuit Analysis. \\n2. Administering exams, grading scripts and conducting problem solving sessions for Circuit Analysis I, Linear System Analysis, Electronic Circuit\", \"location\": \"Norfolk, VA, USA\"}\n",
      "Example response: {\"industry\": \"education\", \"profession\": \"teaching assistant\", \"skills\": [\"student assistance\", \"experimental lab work\", \"exam administration\", \"grading\", \"problem-solving\"], \"tags\": [\"university\", \"teaching assistance\", \"student engagement\", \"lab work\", \"electronic circuits\", \"circuit analysis\", \"exam administration\", \"grading\", \"problem-solving sessions\", \"electronic circuit analysis\", \"linear systems\"]}user\n",
      "\n",
      "{\"company\": \"University of Engineering and Technology Peshawar, Pakistan\", \"title\": \"R&D Consultant\", \"description\": \"UET, Peshawar has undertaken various projects that required the expertise of a R&D based Biomedical Engineer. I provided my expertise to the students and staff in these projects and increased the productivity of the department. Additionally, I \\u2022 Identified the need for 3D printers for the department \\u2022 Investigated 3D printers that would be best suited for the training individuals \\u2022 Designed a certified course to train the students and staff on the essentials of 3D printing \\u2022 Trained individuals including but not limited to, students, professionals and artists\", \"location\": \"Pakistan\"}assistant\n",
      "\n",
      "\n",
      "Encoded input:\n",
      "tensor([[128000, 128006,   9125, 128007,    271,   2675,    527,    459,  15592,\n",
      "          18328,  28175,    304,  42118,  11704,    505,  33867,  21542,     13,\n",
      "           3277,   3984,    449,    459,   3217,     11,    701,   3465,    374,\n",
      "            311,  14532,    323,   8819,   1401,   3649,     11,  21760,    389,\n",
      "          49183,    539,   1120,  11720,   7512,    719,   1101,  18479,   6305,\n",
      "             11,   4279,   5064,  12659,     11,    323,    279,    503,  71921,\n",
      "           1511,    304,    279,  10706,    627,   2520,    279,   2728,   3217,\n",
      "             11,   7068,    264,   4823,   1665,    430,   5764,   8365,   1778,\n",
      "            439,   5064,     11,   4913,     11,   7512,     11,    323,   9681,\n",
      "             13,    578,  33289,   1288,   8881,   2225,   9539,  11224,   7512,\n",
      "            323,  68695,   7512,   3196,    389,    279,   2317,    323,   5064,\n",
      "          40851,     13,  21829,    279,   2768,   8365,    369,    279,   2612,\n",
      "            512,  71616,     25,   9934,    311,   7836,  10743,    505,   2883,\n",
      "            955,    477,   2316,     11,    422,    539,   6089,   9932,    627,\n",
      "          19105,   1362,     25,  23673,    505,    279,   2683,   2316,    323,\n",
      "           4096,    627,  47761,     25,   1796,   2225,   2167,    320,  94732,\n",
      "            398,   9932,      8,    323,  25636,    320,  54340,  11383,   5938,\n",
      "            449,    279,   3560,    477,   5064,   4390,  16309,     25,  30834,\n",
      "           9959,  21513,     11,   2225,  11156,    323,  66251,     11,    430,\n",
      "           7664,    279,   3217,    477,    527,   5938,    449,    279,   5064,\n",
      "            627,   5207,   4823,  14692,     25,   5324,  71864,    794,   4145,\n",
      "          71864,  21841,    330,  97235,    794,   4145,  97235,  21841,    330,\n",
      "          54340,    794,   4482,     27,  30554,     16,  21841,   4145,  30554,\n",
      "             17,  21841,   2564,   1145,    330,  14412,    794,   4482,     27,\n",
      "           4681,     16,  21841,   4145,   4681,     17,  21841,   2564,  24333,\n",
      "            644,   1162,    459,   7180,    374,  14188,   9932,   6463,   8196,\n",
      "             11,    743,   1202,    907,    311,    854,     13,  73177,    279,\n",
      "           1988,  87388,    311,   8819,    279,   9959,   2038,   2085,   6968,\n",
      "            477,  26619,   3649,    539,   3118,    304,    279,   1988,    627,\n",
      "          12834,    420,   9659,    690,    387,   7373,  28598,    279,   1217,\n",
      "            690,   1193,   3493,    264,   4823,   1665,   2085,    904,   4726,\n",
      "          11470,    323,  25283,   1193,    279,  13239,   1988,     13,   5884,\n",
      "           2612,    430,   3250,   9011,  48092,     83,   1833,    279,   5300,\n",
      "           4823,   3645,     11,   4250,    387,  15590,   4726,    323,    690,\n",
      "           1464,    279,   5429,     13,   2100,     11,   1304,   2771,    311,\n",
      "           2744,  49553,    311,    279,   4823,   3645,    912,   5030,     13,\n",
      "           1789,   3187,     11,    422,    279,   1988,   5151,   6782,    912,\n",
      "             11,   7515,  38759,    477,  40815,   1495,     11,    499,   7068,\n",
      "            264,   4823,    449,    682,   8365,    439,    854,     13,  20474,\n",
      "            311,    539,   4018,    477,  11857,    904,   8365,    315,    279,\n",
      "            471,   3645,    627,   8586,    374,    459,   3187,    369,   1268,\n",
      "            279,   2077,    311,    264,   2728,   1988,   2643,   1427,   1093,\n",
      "            512,  13617,   1988,     25,   5324,  10348,    794,    330,  18788,\n",
      "          76521,   3907,    498,    330,   2150,    794,    330,   6777,  12092,\n",
      "          22103,    498,    330,   4789,    794,    330,   1622,  28423,     25,\n",
      "           1144,     77,   1734,     16,     13,   2755,  11330,   4236,    304,\n",
      "          31320,  22772,  27692,   4375,    369,  35269,  28317,  18825,     13,\n",
      "           1144,     77,     17,     13,   7735,   1601,    287,  40786,     11,\n",
      "          66288,  20070,    323,  31474,   3575,  22581,  16079,    369,  28317,\n",
      "          18825,    358,     11,  29363,    744,  18825,     11,  35269,  28317,\n",
      "            498,    330,   2588,    794,    330,  33763,  42031,     11,  21571,\n",
      "             11,   7427,  17122,  13617,   2077,     25,   5324,  71864,    794,\n",
      "            330,  37838,    498,    330,  97235,    794,    330,    668,  12092,\n",
      "          18328,    498,    330,  54340,    794,   4482,  12307,  13291,    498,\n",
      "            330,  87803,  10278,    990,    498,    330,  42716,   8735,    498,\n",
      "            330,  33359,    498,    330,  35686,  99246,   8073,    330,  14412,\n",
      "            794,   4482,    359,   3050,    498,    330,    668,  12092,  13291,\n",
      "            498,    330,  12307,  20392,    498,    330,  14717,    990,    498,\n",
      "            330,  19493,   8535,  46121,    498,    330,     66,  38368,   6492,\n",
      "            498,    330,  42716,   8735,    498,    330,  33359,    498,    330,\n",
      "          35686,  99246,  16079,    498,    330,  19493,   8535,  16622,   6492,\n",
      "            498,    330,  23603,   6067,  93546, 128009, 128006,    882, 128007,\n",
      "            271,   5018,  10348,    794,    330,  14783,    498,    330,   2150,\n",
      "            794,    330,  19805,  17005,   4514,    498,    330,   4789,    794,\n",
      "            854,     11,    330,   2588,    794,    330,  60029,    560,     11,\n",
      "           7188,   9388, 128009, 128006,  78191, 128007,    271]])\n",
      "\n",
      "Decoded input:\n",
      "system\n",
      "\n",
      "You are an AI assistant specialized in analyzing experiences from LinkedIn profiles. When provided with an experience, your task is to interpret and extract key details, focusing on recognizing not just explicit skills but also implicit ones, common industry practices, and the jargon used in the sector.\n",
      "For the given experience, generate a JSON object that includes attributes such as industry, profession, skills, and tags. The extraction should reflect both clearly stated skills and inferred skills based on the context and industry norms. Consider the following attributes for the output:\n",
      "Industry: Try to deduce from company type or title, if not directly mentioned.\n",
      "Profession: Extract from the job title and description.\n",
      "Skills: List both direct (explicitly mentioned) and indirect (skills typically associated with the role or industry).\n",
      "Tags: Include relevant keywords, both technical and contextual, that describe the experience or are associated with the industry.\n",
      "Output JSON Template: {\"industry\": \"<industry>\", \"profession\": \"<profession>\", \"skills\": [\"<skill1>\", \"<skill2>\",...], \"tags\": [\"<tag1>\", \"<tag2>\",...]}\n",
      "In case an attribute is neither mentioned nor obvious, set its value to null. Interpret the input responsibly to extract the relevant information without creating or assuming details not present in the input.\n",
      "Since this generation will be fully automated the user will only provide a JSON object without any further instructions and expects only the resulting input. Any output that doesnâ€™t follow the specified JSON format, cannot be processed further and will break the script. So, make sure to always adhere to the JSON format no matter. For example, if the input fields contain no, garbled or irrelevant text, you generate a JSON with all attributes as null. Remember to not cut or alter any attributes of the return format.\n",
      "Here is an example for how the response to a given input might look like:\n",
      "Example input: {\"company\": \"Old Dominion University\", \"title\": \"Teaching Assistant\", \"description\": \"Key responsibilities: \\n\\n1. Assisting students in executing experimental laboratory works for Electronic Circuit Analysis. \\n2. Administering exams, grading scripts and conducting problem solving sessions for Circuit Analysis I, Linear System Analysis, Electronic Circuit\", \"location\": \"Norfolk, VA, USA\"}\n",
      "Example response: {\"industry\": \"education\", \"profession\": \"teaching assistant\", \"skills\": [\"student assistance\", \"experimental lab work\", \"exam administration\", \"grading\", \"problem-solving\"], \"tags\": [\"university\", \"teaching assistance\", \"student engagement\", \"lab work\", \"electronic circuits\", \"circuit analysis\", \"exam administration\", \"grading\", \"problem-solving sessions\", \"electronic circuit analysis\", \"linear systems\"]}user\n",
      "\n",
      "{\"company\": \"Google\", \"title\": \"Software Engineering Intern\", \"description\": null, \"location\": \"Venice, California\"}assistant\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "    \n",
    "\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(os.getenv(\"LLAMA_3_PATH\"))\n",
    "\n",
    "# Read the system prompt\n",
    "with open('prompt.txt', 'r') as file:\n",
    "    # Read the entire content of the file\n",
    "    sys_prompt = file.read()\n",
    "\n",
    "for experience in test_experiences:\n",
    "    preprocessed_experience = process_experience(experience)\n",
    "    tokenized_input = prepare_experience_for_model_input(\n",
    "        process_experience(experience), sys_prompt, tokenizer)\n",
    "    \n",
    "    print(\"Encoded input:\")\n",
    "    print(tokenized_input)\n",
    "    \n",
    "    print(\"\\nDecoded input:\")\n",
    "    print(tokenizer.decode(tokenized_input[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f2758156a03d2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T17:55:45.095435Z",
     "start_time": "2024-06-17T17:55:05.825330Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "    \n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "\n",
    "# Read the system prompt\n",
    "with open('prompt.txt', 'r') as file:\n",
    "    # Read the entire content of the file\n",
    "    sys_prompt = file.read()\n",
    "\n",
    "# Run the preparation function\n",
    "preprocess_and_save_experiences(\n",
    "    input_file_path=os.getenv(\"INPUT_FILE_PATH\"),\n",
    "    output_path= os.getenv(\"OUTPUT_PATH\"),\n",
    "    system_prompt=sys_prompt,\n",
    "    model_id_or_path='microsoft/Phi-3-mini-128k-instruct'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
