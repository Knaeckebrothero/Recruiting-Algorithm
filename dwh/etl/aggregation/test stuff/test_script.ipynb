{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fea5d3af-97bc-431b-a846-e2fe526a1fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def process_experience(experience_dict: dict):\n",
    "    \"\"\"\n",
    "    Preprocess a experience from a LinkedIn profile by cleaning text fields.\n",
    "    \n",
    "    :param experience_dict: A dictionary containing profile information.\n",
    "\n",
    "    :return: A preprocessed dictionary with cleaned text fields.\n",
    "    \"\"\"\n",
    "    # Define the keys to extract and clean\n",
    "    keys_to_extract = ['company', 'title', 'description', 'location']\n",
    "    \n",
    "    # Initialize an empty dictionary to store the preprocessed data\n",
    "    preprocessed_data = {}\n",
    "    \n",
    "    # Iterate through the required keys\n",
    "    for key in keys_to_extract:\n",
    "        # Extract the value from the profile dictionary or use an empty string if the key is not present\n",
    "        value = experience_dict.get(key, '')\n",
    "        \n",
    "        # Clean up the text:\n",
    "        # - Strip leading and trailing whitespace\n",
    "        # - Replace multiple spaces with a single space\n",
    "        # - Replace new line characters and tabs with a single space\n",
    "        if value:\n",
    "            cleaned_value = re.sub(r'\\s+', ' ', value.strip())\n",
    "        else:\n",
    "            cleaned_value = None\n",
    "        \n",
    "        # Store the cleaned value in the preprocessed data dictionary\n",
    "        preprocessed_data[key] = cleaned_value\n",
    "    \n",
    "    # Return the preprocessed data\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3398158f-dc6a-45cb-909c-42af9861d31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def prepare_experiences_for_model_input(preprocessed_dict: dict, tokenizer: AutoTokenizer):\n",
    "    \"\"\"\n",
    "    A function to prepare the model input based on the preprocessed dictionary.\n",
    "\n",
    "    :param preprocessed_dict: The preprocessed experience as a dictionary information.\n",
    "    :param tokenizer: The tokenizer to use for encoding the input.\n",
    "\n",
    "    :return: The model input as text or tokens.\n",
    "    \"\"\"\n",
    "    # Convert the preprocessed dictionary to a JSON string and construct the prompt\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are an AI assistant specialized in analyzing experiences from LinkedIn profiles. When provided with an entry, your task is to identify and extract key details based on the structure of the input. Use the information given to generate a JSON object that includes specific attributes like company type, job type, tags, and keywords. The output JSON should adhere to this format: {\"company type\": \"<type_of_company_or_null>\", \"job type\": \"<type_of_job_or_null>\", \"tags\": [\"<tag1>\", \"<tag2>\", \"...\"], \"keywords\": [\"<keyword1>\", \"<keyword2>\", \"...\"]} If an attribute is not mentioned in the input, set its value to null. Interpret the input responsibly to extract the relevant information without creating or assuming details not present in the input.\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"For the given dictionary below, please extract the specified attributes: {json.dumps(preprocessed_dict, indent=None)} Please extract the relevant information from the provided dictionary and generate the JSON output accordingly.\"},\n",
    "    ]\n",
    "\n",
    "    # Convert the messages into a prompt\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \"\"\"\n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \"\"\"\n",
    "    # Return the input IDs\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e657e63f-0d73-49a8-a078-0ee6e0af6c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company': 'Limited Brands', 'title': 'Raw Materials Intern- MAST Global', 'description': '- Supported the day to day management of the print and pattern process - Worked cross functionally with Design, Tech Design, and Pre-production - Sat in on sketch line review and created PowerPoints to be sent out to our regional partners in order to receive costing - Communicated with our regional partners to follow up on lab-dips, strike-offs, and sampling as requested by the Design team - Completed numerous projects that were presented to co-workers for eye opening opportunities to further progress the growth of the brand', 'location': 'Columbus, Ohio Area'}\n"
     ]
    }
   ],
   "source": [
    "test_experience = {\n",
    "      \"starts_at\": {\n",
    "        \"day\": 1,\n",
    "        \"month\": 5,\n",
    "        \"year\": 2012\n",
    "      },\n",
    "      \"ends_at\": {\n",
    "        \"day\": 31,\n",
    "        \"month\": 8,\n",
    "        \"year\": 2012\n",
    "      },\n",
    "      \"company\": \"Limited Brands\",\n",
    "      \"company_linkedin_profile_url\": \"https://www.linkedin.com/company/lbrands\",\n",
    "      \"title\": \"Raw Materials Intern- MAST Global\",\n",
    "      \"description\": \"- Supported the day to day management of the print and pattern process\\n- Worked cross functionally with Design, Tech Design, and Pre-production\\n- Sat in on sketch line review and created PowerPoints to be sent out to our regional partners in order to receive costing\\n- Communicated with our regional partners to follow up on lab-dips, strike-offs, and sampling as requested by the Design team\\n- Completed numerous projects that were presented to co-workers for eye opening opportunities to further progress the growth of the brand\",\n",
    "      \"location\": \"Columbus, Ohio Area\",\n",
    "      \"logo_url\": \"https://media-exp1.licdn.com/dms/image/C4E0BAQHD8okj9rA0EQ/company-logo_100_100/0/1547228096275?e=1655942400&v=beta&t=2y-txs4X8PWRyl-UFfX_lGv0JtryM8MA7AQqNN6wlqo\"\n",
    "    }\n",
    "\n",
    "result = process_experience(test_experience)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df291e68-8842-4b02-a1ea-29454afad101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813ac816-ab6d-4cbb-9615-eaa821375637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are an AI assistant specialized in analyzing experiences from LinkedIn profiles. When provided with an entry, your task is to identify and extract key details based on the structure of the input. Use the information given to generate a JSON object that includes specific attributes like company type, job type, tags, and keywords. The output JSON should adhere to this format: {\"company type\": \"<type_of_company_or_null>\", \"job type\": \"<type_of_job_or_null>\", \"tags\": [\"<tag1>\", \"<tag2>\", \"...\"], \"keywords\": [\"<keyword1>\", \"<keyword2>\", \"...\"]} If an attribute is not mentioned in the input, set its value to null. Interpret the input responsibly to extract the relevant information without creating or assuming details not present in the input.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "For the given dictionary below, please extract the specified attributes: {\"company\": \"Limited Brands\", \"title\": \"Raw Materials Intern- MAST Global\", \"description\": \"- Supported the day to day management of the print and pattern process - Worked cross functionally with Design, Tech Design, and Pre-production - Sat in on sketch line review and created PowerPoints to be sent out to our regional partners in order to receive costing - Communicated with our regional partners to follow up on lab-dips, strike-offs, and sampling as requested by the Design team - Completed numerous projects that were presented to co-workers for eye opening opportunities to further progress the growth of the brand\", \"location\": \"Columbus, Ohio Area\"} Please extract the relevant information from the provided dictionary and generate the JSON output accordingly.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Preprocess the experience\n",
    "result = process_experience(test_experience)\n",
    "\n",
    "# Get tokenized input ready for the model\n",
    "tokenized_input = prepare_experiences_for_model_input(result, tokenizer)\n",
    "\n",
    "# Print the tokenized input\n",
    "print(tokenizer.decode(tokenized_input[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b673b77-7311-4c6d-a368-af7c5cb8997f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d88f43b1884bef971561c335a98aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "032ab692-379f-4add-8fc6-8e9682e89d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are an AI assistant specialized in analyzing experiences from LinkedIn profiles. When provided with an entry, your task is to identify and extract key details based on the structure of the input. Use the information given to generate a JSON object that includes specific attributes like company type, job type, tags, and keywords. The output JSON should adhere to this format: {\"company type\": \"<type_of_company_or_null>\", \"job type\": \"<type_of_job_or_null>\", \"tags\": [\"<tag1>\", \"<tag2>\", \"...\"], \"keywords\": [\"<keyword1>\", \"<keyword2>\", \"...\"]} If an attribute is not mentioned in the input, set its value to null. Interpret the input responsibly to extract the relevant information without creating or assuming details not present in the input.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "For the given dictionary below, please extract the specified attributes: {\"company\": \"Limited Brands\", \"title\": \"Raw Materials Intern- MAST Global\", \"description\": \"- Supported the day to day management of the print and pattern process - Worked cross functionally with Design, Tech Design, and Pre-production - Sat in on sketch line review and created PowerPoints to be sent out to our regional partners in order to receive costing - Communicated with our regional partners to follow up on lab-dips, strike-offs, and sampling as requested by the Design team - Completed numerous projects that were presented to co-workers for eye opening opportunities to further progress the growth of the brand\", \"location\": \"Columbus, Ohio Area\"} Please extract the relevant information from the provided dictionary and generate the JSON output accordingly.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Based on the input dictionary, I can extract the following attributes:\n",
      "\n",
      "* Company type: Limited Brands (private company)\n",
      "* Job type: Intern (specifically, Raw Materials Intern)\n",
      "* Tags: [print, pattern, design, tech design, pre-production, lab-dips, strike-offs, sampling, regional partners, costing, PowerPoint]\n",
      "* Keywords: [management, day-to-day, cross-functional, sketch line review, communication, project completion, presentation, growth]\n",
      "\n",
      "Here is the generated JSON output:\n",
      "\n",
      "{\n",
      "\"company type\": \"private\",\n",
      "\"job type\": \"Intern\",\n",
      "\"tags\": [\"print\", \"pattern\", \"design\", \"tech design\", \"pre-production\", \"lab-dips\", \"strike-offs\", \"sampling\", \"regional partners\", \"costing\", \"PowerPoint\"],\n",
      "\"keywords\": [\"management\", \"day-to-day\", \"cross-functional\", \"sketch line review\", \"communication\", \"project completion\", \"presentation\", \"growth\"]\n",
      "}<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# Send tokens to gpu\n",
    "# tokenized_input_gpu = {key: value.to(device) for key, value in tokenized_input.items()}\n",
    "tokenized_input_gpu = tokenized_input.to(device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "# Generate text based on the tokenized input\n",
    "outputs = model.generate(\n",
    "    tokenized_input_gpu, \n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "# Print the generated text\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
