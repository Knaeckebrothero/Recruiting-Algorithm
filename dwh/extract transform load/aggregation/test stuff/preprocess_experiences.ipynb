{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def process_experience(experience_dict: dict):\n",
    "    \"\"\"\n",
    "    Preprocess a experience from a LinkedIn profile by cleaning text fields.\n",
    "    \n",
    "    :param experience_dict: A dictionary containing profile information.\n",
    "\n",
    "    :return: A preprocessed dictionary with cleaned text fields.\n",
    "    \"\"\"\n",
    "    # Define the keys to extract and clean\n",
    "    keys_to_extract = ['company', 'title', 'description', 'location']\n",
    "    \n",
    "    # Initialize an empty dictionary to store the preprocessed data\n",
    "    preprocessed_data = {}\n",
    "    \n",
    "    # Iterate through the required keys\n",
    "    for key in keys_to_extract:\n",
    "        # Extract the value from the profile dictionary or use an empty string if the key is not present\n",
    "        value = experience_dict.get(key, '')\n",
    "        \n",
    "        # Clean up the text:\n",
    "        # - Strip leading and trailing whitespace\n",
    "        # - Replace multiple spaces with a single space\n",
    "        # - Replace new line characters and tabs with a single space\n",
    "        if value:\n",
    "            cleaned_value = re.sub(r'\\s+', ' ', value.strip())\n",
    "        else:\n",
    "            cleaned_value = None\n",
    "        \n",
    "        # Store the cleaned value in the preprocessed data dictionary\n",
    "        preprocessed_data[key] = cleaned_value\n",
    "    \n",
    "    # Return the preprocessed data\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "def prepare_experiences_for_model_input(preprocessed_dict: dict, tokenizer: AutoTokenizer):\n",
    "    \"\"\"\n",
    "    A function to prepare the model input based on the preprocessed dictionary.\n",
    "\n",
    "    :param preprocessed_dict: The preprocessed experience as a dictionary information.\n",
    "    :param tokenizer: The tokenizer to use for encoding the input.\n",
    "\n",
    "    :return: The model input as text or tokens.\n",
    "    \"\"\"\n",
    "    # Convert the preprocessed dictionary to a JSON string and construct the prompt\n",
    "    prompt_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are an AI assistant specialized in analyzing experiences from LinkedIn profiles. When provided with an entry, your task is to identify and extract key details based on the structure of the input. Use the information given to generate a JSON object that includes specific attributes like company type, job type, tags, and keywords. The output JSON should adhere to this format: {\"company type\": \"<type_of_company_or_null>\", \"job type\": \"<type_of_job_or_null>\", \"tags\": [\"<tag1>\", \"<tag2>\", \"...\"], \"keywords\": [\"<keyword1>\", \"<keyword2>\", \"...\"]} If an attribute is not mentioned in the input, set its value to null. Interpret the input responsibly to extract the relevant information without creating or assuming details not present in the input.\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"For the given dictionary below, please extract the specified attributes: {json.dumps(preprocessed_dict, indent=None)} Please extract the relevant information from the provided dictionary and generate the JSON output accordingly.\"},\n",
    "    ]\n",
    "\n",
    "    # Tokenize the prompt\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        prompt_messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Return the input IDs\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company': 'Limited Brands', 'title': 'Raw Materials Intern- MAST Global', 'description': '- Supported the day to day management of the print and pattern process - Worked cross functionally with Design, Tech Design, and Pre-production - Sat in on sketch line review and created PowerPoints to be sent out to our regional partners in order to receive costing - Communicated with our regional partners to follow up on lab-dips, strike-offs, and sampling as requested by the Design team - Completed numerous projects that were presented to co-workers for eye opening opportunities to further progress the growth of the brand', 'location': 'Columbus, Ohio Area'}\n"
     ]
    }
   ],
   "source": [
    "test_experience = {\n",
    "      \"starts_at\": {\n",
    "        \"day\": 1,\n",
    "        \"month\": 5,\n",
    "        \"year\": 2012\n",
    "      },\n",
    "      \"ends_at\": {\n",
    "        \"day\": 31,\n",
    "        \"month\": 8,\n",
    "        \"year\": 2012\n",
    "      },\n",
    "      \"company\": \"Limited Brands\",\n",
    "      \"company_linkedin_profile_url\": \"https://www.linkedin.com/company/lbrands\",\n",
    "      \"title\": \"Raw Materials Intern- MAST Global\",\n",
    "      \"description\": \"- Supported the day to day management of the print and pattern process\\n- Worked cross functionally with Design, Tech Design, and Pre-production\\n- Sat in on sketch line review and created PowerPoints to be sent out to our regional partners in order to receive costing\\n- Communicated with our regional partners to follow up on lab-dips, strike-offs, and sampling as requested by the Design team\\n- Completed numerous projects that were presented to co-workers for eye opening opportunities to further progress the growth of the brand\",\n",
    "      \"location\": \"Columbus, Ohio Area\",\n",
    "      \"logo_url\": \"https://media-exp1.licdn.com/dms/image/C4E0BAQHD8okj9rA0EQ/company-logo_100_100/0/1547228096275?e=1655942400&v=beta&t=2y-txs4X8PWRyl-UFfX_lGv0JtryM8MA7AQqNN6wlqo\"\n",
    "    }\n",
    "\n",
    "result = process_experience(test_experience)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def process_experience(experience_dict: dict):\n",
    "    \"\"\"\n",
    "    Preprocess a experience from a LinkedIn profile by cleaning text fields.\n",
    "    \n",
    "    :param experience_dict: A dictionary containing profile information.\n",
    "\n",
    "    :return: A preprocessed dictionary with cleaned text fields.\n",
    "    \"\"\"\n",
    "    # Define the keys to extract and clean\n",
    "    keys_to_extract = ['company', 'title', 'description', 'location']\n",
    "    \n",
    "    # Initialize an empty dictionary to store the preprocessed data\n",
    "    preprocessed_data = {}\n",
    "    \n",
    "    # Iterate through the required keys\n",
    "    for key in keys_to_extract:\n",
    "        # Extract the value from the profile dictionary or use an empty string if the key is not present\n",
    "        value = experience_dict.get(key, '')\n",
    "        \n",
    "        # Clean up the text:\n",
    "        # - Strip leading and trailing whitespace\n",
    "        # - Replace multiple spaces with a single space\n",
    "        # - Replace new line characters and tabs with a single space\n",
    "        if value:\n",
    "            cleaned_value = re.sub(r'\\s+', ' ', value.strip())\n",
    "        else:\n",
    "            cleaned_value = None\n",
    "        \n",
    "        # Store the cleaned value in the preprocessed data dictionary\n",
    "        preprocessed_data[key] = cleaned_value\n",
    "    \n",
    "    # Return the preprocessed data\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[128000, 128006,   9125, 128007,    271,   2675,    527,    459,  15592,\n",
      "          18328,  28175,    304,  42118,  11704,    505,  33867,  21542,     13,\n",
      "           3277,   3984,    449,    459,   4441,     11,    701,   3465,    374,\n",
      "            311,  10765,    323,   8819,   1401,   3649,   3196,    389,    279,\n",
      "           6070,    315,    279,   1988,     13,   5560,    279,   2038,   2728,\n",
      "            311,   7068,    264,   4823,   1665,    430,   5764,   3230,   8365,\n",
      "           1093,   2883,    955,     11,   2683,    955,     11,   9681,     11,\n",
      "            323,  21513,     13,    578,   2612,   4823,   1288,  49553,    311,\n",
      "            420,   3645,     25,   5324,  10348,    955,    794,   4145,   1337,\n",
      "           3659,  34503,   8908,  15514,  21841,    330,   8975,    955,    794,\n",
      "           4145,   1337,   3659,  20916,   8908,  15514,  21841,    330,  14412,\n",
      "            794,   4482,     27,   4681,     16,  21841,   4145,   4681,     17,\n",
      "          21841,  39813,   8073,    330,  30095,    794,   4482,     27,  20454,\n",
      "             16,  21841,   4145,  20454,     17,  21841,  39813,  93546,   1442,\n",
      "            459,   7180,    374,    539,   9932,    304,    279,   1988,     11,\n",
      "            743,   1202,    907,    311,    854,     13,  73177,    279,   1988,\n",
      "          87388,    311,   8819,    279,   9959,   2038,   2085,   6968,    477,\n",
      "          26619,   3649,    539,   3118,    304,    279,   1988,     13, 128009,\n",
      "         128006,    882, 128007,    271,   2520,    279,   2728,  11240,   3770,\n",
      "             11,   4587,   8819,    279,   5300,   8365,     25,   5324,  10348,\n",
      "            794,    330,  75577,  55332,    498,    330,   2150,    794,    330,\n",
      "          20613,  32009,   4514,     12,    386,   6483,   8121,    498,    330,\n",
      "           4789,    794,   6660,  50080,    279,   1938,    311,   1938,   6373,\n",
      "            315,    279,   1194,    323,   5497,   1920,    482,   5664,    291,\n",
      "           5425,    734,    750,    449,   7127,     11,  17829,   7127,     11,\n",
      "            323,   5075,  70666,    482,  13479,    304,    389,  26610,   1584,\n",
      "           3477,    323,   3549,   7572,  11665,    311,    387,   3288,    704,\n",
      "            311,   1057,  15481,   8717,    304,   2015,    311,   5371,  54824,\n",
      "            482,  16838,    660,    449,   1057,  15481,   8717,    311,   1833,\n",
      "            709,    389,  10278,   1773,   3153,     11,  13471,  65039,     11,\n",
      "            323,  25936,    439,  11472,    555,    279,   7127,   2128,    482,\n",
      "          46594,  12387,   7224,    430,   1051,  10666,    311,   1080,  63384,\n",
      "            369,   8071,   8736,  10708,    311,   4726,   5208,    279,   6650,\n",
      "            315,    279,   6883,    498,    330,   2588,    794,    330,     34,\n",
      "           1152,  10551,     11,  14689,  12299,   9388,   5321,   8819,    279,\n",
      "           9959,   2038,    505,    279,   3984,  11240,    323,   7068,    279,\n",
      "           4823,   2612,  28178,     13, 128009, 128006,  78191, 128007,    271]])\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are an AI assistant specialized in analyzing experiences from LinkedIn profiles. When provided with an entry, your task is to identify and extract key details based on the structure of the input. Use the information given to generate a JSON object that includes specific attributes like company type, job type, tags, and keywords. The output JSON should adhere to this format: {\"company type\": \"<type_of_company_or_null>\", \"job type\": \"<type_of_job_or_null>\", \"tags\": [\"<tag1>\", \"<tag2>\", \"...\"], \"keywords\": [\"<keyword1>\", \"<keyword2>\", \"...\"]} If an attribute is not mentioned in the input, set its value to null. Interpret the input responsibly to extract the relevant information without creating or assuming details not present in the input.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "For the given dictionary below, please extract the specified attributes: {\"company\": \"Limited Brands\", \"title\": \"Raw Materials Intern- MAST Global\", \"description\": \"- Supported the day to day management of the print and pattern process - Worked cross functionally with Design, Tech Design, and Pre-production - Sat in on sketch line review and created PowerPoints to be sent out to our regional partners in order to receive costing - Communicated with our regional partners to follow up on lab-dips, strike-offs, and sampling as requested by the Design team - Completed numerous projects that were presented to co-workers for eye opening opportunities to further progress the growth of the brand\", \"location\": \"Columbus, Ohio Area\"} Please extract the relevant information from the provided dictionary and generate the JSON output accordingly.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n",
      "tensor([[128000, 128006,   9125, 128007,    271,   2675,    527,    459,  15592,\n",
      "          18328,  28175,    304,  42118,  11704,    505,  33867,  21542,     13,\n",
      "           3277,   3984,    449,    459,   4441,     11,    701,   3465,    374,\n",
      "            311,  10765,    323,   8819,   1401,   3649,   3196,    389,    279,\n",
      "           6070,    315,    279,   1988,     13,   5560,    279,   2038,   2728,\n",
      "            311,   7068,    264,   4823,   1665,    430,   5764,   3230,   8365,\n",
      "           1093,   2883,    955,     11,   2683,    955,     11,   9681,     11,\n",
      "            323,  21513,     13,    578,   2612,   4823,   1288,  49553,    311,\n",
      "            420,   3645,     25,   5324,  10348,    955,    794,   4145,   1337,\n",
      "           3659,  34503,   8908,  15514,  21841,    330,   8975,    955,    794,\n",
      "           4145,   1337,   3659,  20916,   8908,  15514,  21841,    330,  14412,\n",
      "            794,   4482,     27,   4681,     16,  21841,   4145,   4681,     17,\n",
      "          21841,  39813,   8073,    330,  30095,    794,   4482,     27,  20454,\n",
      "             16,  21841,   4145,  20454,     17,  21841,  39813,  93546,   1442,\n",
      "            459,   7180,    374,    539,   9932,    304,    279,   1988,     11,\n",
      "            743,   1202,    907,    311,    854,     13,  73177,    279,   1988,\n",
      "          87388,    311,   8819,    279,   9959,   2038,   2085,   6968,    477,\n",
      "          26619,   3649,    539,   3118,    304,    279,   1988,     13, 128009,\n",
      "         128006,    882, 128007,    271,   2520,    279,   2728,  11240,   3770,\n",
      "             11,   4587,   8819,    279,   5300,   8365,     25,   5324,  10348,\n",
      "            794,    330,  75577,  55332,    498,    330,   2150,    794,    330,\n",
      "          20613,  32009,   4514,     12,    386,   6483,   8121,    498,    330,\n",
      "           4789,    794,   6660,  50080,    279,   1938,    311,   1938,   6373,\n",
      "            315,    279,   1194,    323,   5497,   1920,    482,   5664,    291,\n",
      "           5425,    734,    750,    449,   7127,     11,  17829,   7127,     11,\n",
      "            323,   5075,  70666,    482,  13479,    304,    389,  26610,   1584,\n",
      "           3477,    323,   3549,   7572,  11665,    311,    387,   3288,    704,\n",
      "            311,   1057,  15481,   8717,    304,   2015,    311,   5371,  54824,\n",
      "            482,  16838,    660,    449,   1057,  15481,   8717,    311,   1833,\n",
      "            709,    389,  10278,   1773,   3153,     11,  13471,  65039,     11,\n",
      "            323,  25936,    439,  11472,    555,    279,   7127,   2128,    482,\n",
      "          46594,  12387,   7224,    430,   1051,  10666,    311,   1080,  63384,\n",
      "            369,   8071,   8736,  10708,    311,   4726,   5208,    279,   6650,\n",
      "            315,    279,   6883,    498,    330,   2588,    794,    330,     34,\n",
      "           1152,  10551,     11,  14689,  12299,   9388,   5321,   8819,    279,\n",
      "           9959,   2038,    505,    279,   3984,  11240,    323,   7068,    279,\n",
      "           4823,   2612,  28178,     13, 128009, 128006,  78191, 128007,    271]])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_id = os.getenv(\"LLAMA_3_PATH\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Preprocess the experience\n",
    "result = process_experience(test_experience)\n",
    "\n",
    "# Get tokenized input ready for the model\n",
    "tokenized_input = prepare_experiences_for_model_input(result, tokenizer)\n",
    "\n",
    "# Print the tokenized input\n",
    "print(tokenized_input)\n",
    "\n",
    "# Print the tokenized input\n",
    "print(tokenizer.decode(tokenized_input[0]))\n",
    "\n",
    "# Print the tokenized input\n",
    "print(tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "\n",
    "# Set the device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ").to(device)\n",
    "\n",
    "# Generate text based on the tokenized input\n",
    "outputs = model.generate(tokenized_input) \n",
    "\n",
    "# Print the generated text\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_files = 'path_to_input_file.json'\n",
    "output_files = 'path_to_output_file.json'\n",
    "\n",
    "# Open the input JSON file\n",
    "with open(input_files, 'r') as file:\n",
    "    data = json.load(file)  # Load the data from JSON file\n",
    "\n",
    "results = []  # Initialize an empty list to hold the results\n",
    "\n",
    "# Iterate over each profile in the data\n",
    "for profile in data:\n",
    "    profile_id = profile[\"_id\"][\"$oid\"]  # Extract the MongoDB Object ID\n",
    "\n",
    "    # Simulate processing the experiences and generate a dummy result\n",
    "    # Here you might replace this with the actual processing logic\n",
    "    result = {\n",
    "        \"_id\": profile_id,\n",
    "        \"results\": \"Processed results here\"  # Placeholder for your actual results\n",
    "    }\n",
    "    results.append(result)  # Append the processed result to the list\n",
    "\n",
    "# Save the processed data to a new JSON file\n",
    "with open(output_file_path, 'w') as outfile:\n",
    "    json.dump(results, outfile, indent=4)  # Write JSON data with indentation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
